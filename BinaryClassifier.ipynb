{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7f618d1-666f-43fa-9265-c4e470c72f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9500535-abd4-4331-9875-e03860a26406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cab1330-0d65-4f0e-9f56-5de184862a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>home_team_score</th>\n",
       "      <th>visitor_team_score</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>visitor_team_id</th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>height_feet</th>\n",
       "      <th>height_inches</th>\n",
       "      <th>last_name</th>\n",
       "      <th>position</th>\n",
       "      <th>team</th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>team_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>126</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>Jabari</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bird</td>\n",
       "      <td>G</td>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>126</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>494</td>\n",
       "      <td>Michael</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>126</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>Jabari</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bird</td>\n",
       "      <td>G</td>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>126</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>494</td>\n",
       "      <td>Michael</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>126</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>669</td>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bagley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12555699</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>56677805</td>\n",
       "      <td>Javon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freeman-Liberty</td>\n",
       "      <td>G</td>\n",
       "      <td>TOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12555700</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>38017717</td>\n",
       "      <td>Ron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harper Jr.</td>\n",
       "      <td>F</td>\n",
       "      <td>TOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12555701</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>373</td>\n",
       "      <td>Jakob</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Poeltl</td>\n",
       "      <td>C</td>\n",
       "      <td>TOR</td>\n",
       "      <td>230.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12555702</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>416</td>\n",
       "      <td>Pascal</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Siakam</td>\n",
       "      <td>F</td>\n",
       "      <td>TOR</td>\n",
       "      <td>230.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12555703</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>38017710</td>\n",
       "      <td>Christian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Koloko</td>\n",
       "      <td>C</td>\n",
       "      <td>TOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12555704 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  home_team_score  visitor_team_score  home_team_id  \\\n",
       "0        2019-01-30              126                  94             2   \n",
       "1        2019-01-30              126                  94             2   \n",
       "2        2019-01-30              126                  94             2   \n",
       "3        2019-01-30              126                  94             2   \n",
       "4        2019-01-30              126                  94             2   \n",
       "...             ...              ...                 ...           ...   \n",
       "12555699 2024-03-31                0                   0            28   \n",
       "12555700 2024-03-31                0                   0            28   \n",
       "12555701 2024-03-31                0                   0            28   \n",
       "12555702 2024-03-31                0                   0            28   \n",
       "12555703 2024-03-31                0                   0            28   \n",
       "\n",
       "          visitor_team_id        id first_name  height_feet  height_inches  \\\n",
       "0                       4        47     Jabari          NaN            NaN   \n",
       "1                       4       494    Michael          NaN            NaN   \n",
       "2                       4        47     Jabari          NaN            NaN   \n",
       "3                       4       494    Michael          NaN            NaN   \n",
       "4                       4       669       John          NaN            NaN   \n",
       "...                   ...       ...        ...          ...            ...   \n",
       "12555699               23  56677805      Javon          NaN            NaN   \n",
       "12555700               23  38017717        Ron          NaN            NaN   \n",
       "12555701               23       373      Jakob          7.0            0.0   \n",
       "12555702               23       416     Pascal          6.0            9.0   \n",
       "12555703               23  38017710  Christian          NaN            NaN   \n",
       "\n",
       "                last_name position team  weight_pounds  team_id  \n",
       "0                    Bird        G  BOS            NaN        2  \n",
       "1                   Smith      NaN  BOS            NaN        2  \n",
       "2                    Bird        G  BOS            NaN        2  \n",
       "3                   Smith      NaN  BOS            NaN        2  \n",
       "4                  Bagley      NaN  BOS            NaN        2  \n",
       "...                   ...      ...  ...            ...      ...  \n",
       "12555699  Freeman-Liberty        G  TOR            NaN       28  \n",
       "12555700       Harper Jr.        F  TOR            NaN       28  \n",
       "12555701           Poeltl        C  TOR          230.0       28  \n",
       "12555702           Siakam        F  TOR          230.0       28  \n",
       "12555703           Koloko        C  TOR            NaN       28  \n",
       "\n",
       "[12555704 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load datasets\n",
    "games_data = pd.read_csv(\"games.csv\")\n",
    "teams_data = pd.read_csv(\"team.csv\")\n",
    "\n",
    "# Define columns to be selected\n",
    "selected_columns_games = ['date', 'home_team_score', 'visitor_team_score', 'home_team_id', 'visitor_team_id']\n",
    "\n",
    "# Merge datasets\n",
    "merged_data = pd.merge(games_data[selected_columns_games], teams_data, how='inner', left_on='home_team_id', right_on='team_id')\n",
    "\n",
    "# Ensure 'date' column is in datetime format and sort by date and keep relevant data(last 3-4 seasons)\n",
    "merged_data['date'] = pd.to_datetime(merged_data['date']).dt.tz_localize(None)\n",
    "\n",
    "# View the final dataframe\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_date_features(merged_data):\n",
    "    # Ensure 'date' column is in datetime format and sort by date\n",
    "    merged_data = merged_data.sort_values(by='date')\n",
    "    \n",
    "    # Filter out the games prior to 2020-01-01 (or any other start date you prefer)\n",
    "    start_date = pd.to_datetime(\"2020-01-01\")\n",
    "    merged_data = merged_data[merged_data['date'] >= start_date]\n",
    "\n",
    "    # Add a season column to indicate the season year\n",
    "    merged_data['season'] = merged_data['date'].dt.year\n",
    "\n",
    "    # Outcome column where 1 = home win, 0 = visitor win\n",
    "    merged_data['outcome'] = (merged_data['home_team_score'] > merged_data['visitor_team_score']).astype(int)\n",
    "\n",
    "    # Initialize columns for running win totals, games played, and win percentages\n",
    "    merged_data['home_running_wins'] = 0\n",
    "    merged_data['visitor_running_wins'] = 0\n",
    "    merged_data['home_running_games'] = 0\n",
    "    merged_data['visitor_running_games'] = 0\n",
    "    merged_data['home_seasonal_win_percentage'] = 0\n",
    "    merged_data['visitor_seasonal_win_percentage'] = 0\n",
    "\n",
    "    # Calculate running win totals for home and visitor teams\n",
    "    merged_data['home_running_wins'] = merged_data.groupby('home_team_id')['outcome'].cumsum()\n",
    "    merged_data['visitor_running_wins'] = merged_data.groupby('visitor_team_id')['outcome'].cumsum()\n",
    "\n",
    "    # Calculate cumulative count of games played for home and visitor teams\n",
    "    merged_data['home_running_games'] = merged_data.groupby('home_team_id').cumcount() + 1\n",
    "    merged_data['visitor_running_games'] = merged_data.groupby('visitor_team_id').cumcount() + 1\n",
    "\n",
    "    # Calculate seasonal win percentage for home and visitor teams\n",
    "    merged_data['home_seasonal_win_percentage'] = merged_data['home_running_wins'] / merged_data['home_running_games']\n",
    "    merged_data['visitor_seasonal_win_percentage'] = merged_data['visitor_running_wins'] / merged_data['visitor_running_games']\n",
    "\n",
    "    # Add playoff hunt status: 1 if win percentage >= 50%, else 0\n",
    "    merged_data['home_in_playoff_hunt'] = (merged_data['home_seasonal_win_percentage'] >= 0.500).astype(int)\n",
    "    merged_data['visitor_in_playoff_hunt'] = (merged_data['visitor_seasonal_win_percentage'] >= 0.500).astype(int)\n",
    "\n",
    "    # Optionally drop columns you no longer need\n",
    "    merged_data = merged_data.drop(['home_running_wins', 'visitor_running_wins', 'home_running_games', 'visitor_running_games'], axis=1)\n",
    "    merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
    "    season_end_date = pd.to_datetime('2025-04-15')\n",
    "\n",
    "    # 1. Binary classification for Playoff vs Regular Season (Playoffs start in April)\n",
    "    merged_data['is_playoff'] = merged_data['date'].dt.month.apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "    # 2. Calculate days remaining in the season\n",
    "    merged_data['days_remaining'] = (season_end_date - merged_data['date']).dt.days\n",
    "\n",
    "    # 3. Weights based on how close the game is to the end of the regular season\n",
    "    merged_data['late_season_weight'] = np.maximum(0, 1 - (merged_data['days_remaining'] / 365))  # Normalize by 365 days\n",
    "\n",
    "    # 4. Example: Assume a team is in the playoff hunt if their win percentage is >= 0.500\n",
    "    merged_data['team_win_percentage'] = merged_data['team_wins'] / merged_data['team_games_played']\n",
    "    merged_data['in_playoff_hunt'] = merged_data['team_win_percentage'].apply(lambda x: 1 if x >= 0.500 else 0)\n",
    "\n",
    "    # 5. Combining the late-season and playoff hunt feature\n",
    "    merged_data['late_playoff_weight'] = merged_data['late_season_weight'] * merged_data['in_playoff_hunt']\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309c9e2",
   "metadata": {},
   "source": [
    "Predictor for player statistics and team statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "# TODO: test the class .95.\n",
    "\n",
    "# Define the Dataset class\n",
    "class PlayerDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "# Define the Model class\n",
    "class PlayerStatsPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PlayerStatsPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Helper function to prepare the data for model training\n",
    "def prepare_data(player_data, merged_data, selected_features, target_statistic):\n",
    "    # Merge player stats with team-based features (e.g., from merged_data)\n",
    "    merged_features = pd.merge(player_data, merged_data, left_on='team_id', right_on='home_team_id', how='inner')\n",
    "    \n",
    "    # Split the features and target\n",
    "    X = merged_features[selected_features]\n",
    "    y = merged_features[target_statistic]\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b5fc6e",
   "metadata": {},
   "source": [
    "Training Baseline model with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9c0e8f-d104-44d6-9d0b-8a2123e16434",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'team_wins'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ryan_pc\\miniforge3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'team_wins'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m merged_data = \u001b[43mdate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#split data\u001b[39;00m\n\u001b[32m      4\u001b[39m X = merged_data.drop(\u001b[33m\"\u001b[39m\u001b[33moutcome\u001b[39m\u001b[33m\"\u001b[39m, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mdate_features\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     14\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mlate_season_weight\u001b[39m\u001b[33m'\u001b[39m] = np.maximum(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m - (df[\u001b[33m'\u001b[39m\u001b[33mdays_remaining\u001b[39m\u001b[33m'\u001b[39m] / \u001b[32m365\u001b[39m))  \u001b[38;5;66;03m# Normalize by 365 days\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 4. Example: Assume a team is in the playoff hunt if their win percentage is >= 0.500\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mteam_win_percentage\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mteam_wins\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m / df[\u001b[33m'\u001b[39m\u001b[33mteam_games_played\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33min_playoff_hunt\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mteam_win_percentage\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x >= \u001b[32m0.500\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 5. Combining the late-season and playoff hunt feature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ryan_pc\\miniforge3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ryan_pc\\miniforge3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'team_wins'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create an instance of the model and initialize parameters\n",
    "# TODO: Implement training model, make sure player data contains neccessary features, make sure merged_df has necessary date features, and then create the model, figure out target stat(win outcome percentage accuracy)\n",
    "input_size = len(selected_features) + len(merged_data.columns)  # player stats + team/date features\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Assuming 'player_data' contains the player stats and 'merged_data' has the features\n",
    "X_train, X_test, y_train, y_test = prepare_data(player_data, merged_data, selected_features, target_statistic)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = PlayerDataset(X_train, y_train)\n",
    "test_dataset = PlayerDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = PlayerStatsPredictor(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ed121",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be2c86-8cec-409e-acb4-d605271c66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    for inputs, targets in test_loader:\n",
    "        predictions = model(inputs)\n",
    "        all_predictions.extend(predictions.numpy())\n",
    "        all_targets.extend(targets.numpy())\n",
    "\n",
    "# Calculate Mean Squared Error on the test set\n",
    "mse = mean_squared_error(all_targets, all_predictions)\n",
    "print(f'Mean Squared Error on Test Set: {mse:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b039b",
   "metadata": {},
   "source": [
    "Test player prediction on single player Ex. Lebron James"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e58791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict player statistics for a given player\n",
    "def predict_player_stat(player_name, player_data, model, selected_features):\n",
    "    player_names = player_name.split()\n",
    "    player_features = player_data[(player_data['player.first_name'] == player_names[0]) & \n",
    "                                  (player_data['player.last_name'] == player_names[1])][selected_features].values    \n",
    "    player_features_tensor = torch.tensor(player_features, dtype=torch.float32)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted_stat = model(player_features_tensor)\n",
    "    \n",
    "    predicted_stat = predicted_stat.numpy()\n",
    "    return predicted_stat\n",
    "\n",
    "# Example: Predicting player statistics for a given player\n",
    "player_name = 'LeBron James'  # Adjust this with the player's name you want to predict for\n",
    "predicted_stats = predict_player_stat(player_name, player_data, model, selected_features)\n",
    "print(f'Predicted Stats for {player_name}: {predicted_stats[0][0]:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
